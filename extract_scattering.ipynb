{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from kymatio.torch import Scattering2D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_size': 256,\n",
    "    'num_worker': 32,\n",
    "    'random_seed': 8771795,\n",
    "    'augmentation': False,\n",
    "    'num_epoch': 10,\n",
    "    'device': 'cuda'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "torch.random.manual_seed(args['random_seed'])\n",
    "\n",
    "# Define transformation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_valid_transform = test_transform\n",
    "if args['augmentation']:\n",
    "    train_valid_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((28,28)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "# Load dataset\n",
    "require_download = os.path.exists('./dataset')\n",
    "train_valid_dataset = torchvision.datasets.FashionMNIST('./dataset', train=True, transform=train_valid_transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST('./dataset', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# Split train and validation\n",
    "torch.random.manual_seed(args['random_seed'])\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_valid_dataset, [54000, 6000])\n",
    "\n",
    "# Generate dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True, num_workers=args['num_worker'])\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=args['num_worker'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False, num_workers=args['num_worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:01<00:00, 135.97it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.30it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 48.68it/s]\n",
      "100%|██████████| 211/211 [00:05<00:00, 36.72it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 19.89it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.39it/s]\n",
      "100%|██████████| 211/211 [00:13<00:00, 15.75it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.65it/s]\n",
      "100%|██████████| 40/40 [00:03<00:00, 13.24it/s]\n",
      "100%|██████████| 211/211 [00:24<00:00,  8.45it/s]\n",
      "100%|██████████| 24/24 [00:03<00:00,  7.08it/s]\n",
      "100%|██████████| 40/40 [00:05<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./features'):\n",
    "    os.mkdir('./features')\n",
    "    \n",
    "for j in range(1,5):\n",
    "    train_feats, valid_feats, test_feats = [], [], []\n",
    "    model = Scattering2D(J=j, shape=(28, 28)).to(args['device'])\n",
    "\n",
    "    # Train\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(args['device']), y.to(args['device'])\n",
    "        yp = model(x) \n",
    "        train_feats.append(yp)\n",
    "    train_feats = torch.cat(train_feats, dim=0)\n",
    "\n",
    "    # Valid\n",
    "    for x, y in tqdm(valid_loader):\n",
    "        x, y = x.to(args['device']), y.to(args['device'])\n",
    "        yp = model(x)\n",
    "        valid_feats.append(yp)\n",
    "    valid_feats = torch.cat(valid_feats, dim=0)\n",
    "\n",
    "    # Test\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x, y = x.to(args['device']), y.to(args['device'])\n",
    "        yp = model(x)\n",
    "        test_feats.append(yp)\n",
    "    test_feats = torch.cat(test_feats, dim=0)\n",
    "    \n",
    "    torch.save((train_feats, valid_feats, test_feats), open(f'./features/scaterring_J{j}.pt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (env_py3.7)",
   "language": "python",
   "name": "env_py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
